Args in experiment:
Namespace(is_training=1, model_id='ili_E3k_36_36', model='B6autoformer', slow_model='AutoformerS1', data='custom', root_path='./dataset/illness/', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints1/', seq_len=36, label_len=18, pred_len=36, bucket_size=4, n_hashes=4, enc_in=7, dec_in=7, c_out=7, d_model=256, n_learner=3, n_heads=8, urt_heads=1, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=20, batch_size=32, patience=3, learning_rate=0.001, anomaly=10.0, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', fix_seed='2023')
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.00389789473592771
stdev: 0.009013802066105327
stdev: 0.0062924702990542645
stdev: 0.0021393648415386213
stdev: 0.0022720710031736715
stdev: 0.005211060330473793
stdev: 0.0011988069545634107
stdev: 0.0075454724139043545
stdev: 0.0057194860804500045
stdev: 0.005904417149294411
stdev: 0.005107359343831957
stdev: 0.005512440381976261
stdev: 0.004550216975213523
stdev: 0.0023605507292126858
stdev: 0.004247876594197319
stdev: 0.0024586930618065903
stdev: 0.004041628237529124
stdev: 0.0026229095268389944
stdev: 0.004518922610259292
stdev: 0.0013208338936367935
stdev: 0.006083754840266261
stdev: 0.002831153426857548
stdev: 0.003885440118990134
stdev: 0.0043890740448641035
stdev: 0.002656487276448098
stdev: 0.0019355665271763543
stdev: 0.00509434502092531
stdev: 0.002762774537423048
stdev: 0.004406728802978894
stdev: 0.009374787633533964
stdev: 0.007841437418818487
stdev: 0.007936878138929144
stdev: 0.006370305015692377
stdev: 0.00812459032495573
stdev: 0.008293044732903869
stdev: 0.00982501503183741
stdev: 0.008963067286477621
stdev: 0.0019882101292753767
>>>>>>>start training : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Epoch: 1 cost time: 5.8021321296691895
Epoch: 1, Steps: 18 | Train Loss: 1.0043472 Vali Loss: 0.5779889 Test Loss: 3.9713712
Validation loss decreased (inf --> 0.577989).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.6921823024749756
Epoch: 2, Steps: 18 | Train Loss: 0.7622583 Vali Loss: 0.4134313 Test Loss: 3.5603485
Validation loss decreased (0.577989 --> 0.413431).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.683077096939087
Epoch: 3, Steps: 18 | Train Loss: 0.5901645 Vali Loss: 0.3867172 Test Loss: 3.1129334
Validation loss decreased (0.413431 --> 0.386717).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.6169636249542236
Epoch: 4, Steps: 18 | Train Loss: 0.4963813 Vali Loss: 0.3216163 Test Loss: 3.2425418
Validation loss decreased (0.386717 --> 0.321616).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.622941017150879
Epoch: 5, Steps: 18 | Train Loss: 0.4578299 Vali Loss: 0.2981080 Test Loss: 3.0329986
Validation loss decreased (0.321616 --> 0.298108).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.5268211364746094
Epoch: 6, Steps: 18 | Train Loss: 0.4311595 Vali Loss: 0.3016694 Test Loss: 3.0404859
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.7328402996063232
Epoch: 7, Steps: 18 | Train Loss: 0.4265830 Vali Loss: 0.2934221 Test Loss: 2.9804063
Validation loss decreased (0.298108 --> 0.293422).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.4542148113250732
Epoch: 8, Steps: 18 | Train Loss: 0.4135449 Vali Loss: 0.2613957 Test Loss: 2.9944367
Validation loss decreased (0.293422 --> 0.261396).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.5568325519561768
Epoch: 9, Steps: 18 | Train Loss: 0.4255500 Vali Loss: 0.2744873 Test Loss: 3.0022986
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.4092774391174316
Epoch: 10, Steps: 18 | Train Loss: 0.4125924 Vali Loss: 0.2787938 Test Loss: 3.0055747
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 3.3135688304901123
Epoch: 11, Steps: 18 | Train Loss: 0.4169658 Vali Loss: 0.3124362 Test Loss: 2.9994586
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:2.9885897636413574, mae:1.189521074295044
Test learner: 0 test 158
mse:3.7528858184814453, mae:1.3725677728652954
Test learner: 1 test 158
mse:5.215574264526367, mae:1.6526117324829102
Test learner: 2 test 158
mse:8.044790267944336, mae:1.9197909832000732
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.008377396846064557
stdev: 0.0037685160134432335
stdev: 0.0033534520018520136
stdev: 0.004651511897972907
stdev: 0.0059807834357843105
stdev: 0.006629737969635403
stdev: 0.0017088422226270309
stdev: 0.009750550838549834
stdev: 0.004701799488894027
stdev: 0.007494979629638079
stdev: 0.0069695873238060976
stdev: 0.002964027383766686
stdev: 0.0026845528338548886
stdev: 0.0075680131488307465
stdev: 0.008769819366784014
stdev: 0.004525483277957965
stdev: 0.0019904330214741035
stdev: 0.009215123532215028
stdev: 0.004213053899166476
stdev: 0.00471665961836313
stdev: 0.002651947243965037
stdev: 0.006273912429908084
stdev: 0.008701037619831889
stdev: 0.008107130937207881
stdev: 0.0017905818133238257
stdev: 0.009396939452102501
stdev: 0.005499560265466813
stdev: 0.00427831290271721
stdev: 0.005352455714557049
stdev: 0.005637021321999348
stdev: 0.009951791209076886
stdev: 0.007780630990366405
stdev: 0.004292379242223742
stdev: 0.006502357732507919
stdev: 0.004776502149535791
stdev: 0.0018250904989186452
stdev: 0.005813685268892471
stdev: 0.004066877967828311
>>>>>>>start training : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Epoch: 1 cost time: 3.3692209720611572
Epoch: 1, Steps: 18 | Train Loss: 0.9091573 Vali Loss: 0.5944352 Test Loss: 4.1197219
Validation loss decreased (inf --> 0.594435).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.388439178466797
Epoch: 2, Steps: 18 | Train Loss: 0.9213540 Vali Loss: 0.4397266 Test Loss: 3.4807682
Validation loss decreased (0.594435 --> 0.439727).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.43217134475708
Epoch: 3, Steps: 18 | Train Loss: 0.5964880 Vali Loss: 0.3362239 Test Loss: 3.2598119
Validation loss decreased (0.439727 --> 0.336224).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.686892509460449
Epoch: 4, Steps: 18 | Train Loss: 0.5268442 Vali Loss: 0.3241903 Test Loss: 2.9959731
Validation loss decreased (0.336224 --> 0.324190).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.576622724533081
Epoch: 5, Steps: 18 | Train Loss: 0.5106411 Vali Loss: 0.2483487 Test Loss: 2.9556942
Validation loss decreased (0.324190 --> 0.248349).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.743687391281128
Epoch: 6, Steps: 18 | Train Loss: 0.4615748 Vali Loss: 0.3362547 Test Loss: 2.9602158
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.490528106689453
Epoch: 7, Steps: 18 | Train Loss: 0.4490257 Vali Loss: 0.3000036 Test Loss: 2.9346225
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.4435081481933594
Epoch: 8, Steps: 18 | Train Loss: 0.4409584 Vali Loss: 0.2782156 Test Loss: 2.9293020
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:2.9453999996185303, mae:1.1782835721969604
Test learner: 0 test 158
mse:4.585245132446289, mae:1.5026359558105469
Test learner: 1 test 158
mse:5.085769176483154, mae:1.6159846782684326
Test learner: 2 test 158
mse:5.045583724975586, mae:1.7041367292404175
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.0011650689180082222
stdev: 0.006431073584825836
stdev: 0.009296255556933971
stdev: 0.0035322771822149926
stdev: 0.008513208830001034
stdev: 0.005946603917867569
stdev: 0.0011961191436278358
stdev: 0.00412353900576364
stdev: 0.005950313122404854
stdev: 0.0011188506801521948
stdev: 0.0074430343649941446
stdev: 0.0027079930481982636
stdev: 0.007682203661959859
stdev: 0.006664882330555672
stdev: 0.004259655370821585
stdev: 0.00664326451334338
stdev: 0.005633962771652832
stdev: 0.009054165861432033
stdev: 0.005667988831155426
stdev: 0.006466682624266456
stdev: 0.005273343986990874
stdev: 0.007386316292472245
stdev: 0.002037184386106846
stdev: 0.007595146617364617
stdev: 0.00890238282297522
stdev: 0.005671575591892068
stdev: 0.00712447093627573
stdev: 0.004920022416427312
stdev: 0.009745868992401152
stdev: 0.004286721395051589
stdev: 0.0066044169297078585
stdev: 0.0033246408939077436
stdev: 0.007132089628265548
stdev: 0.00888932737378869
stdev: 0.0031804164498893846
stdev: 0.0022836897491352237
stdev: 0.008428502005730955
stdev: 0.0051889613250137865
>>>>>>>start training : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Epoch: 1 cost time: 3.6880311965942383
Epoch: 1, Steps: 18 | Train Loss: 0.9455918 Vali Loss: 0.6260539 Test Loss: 3.6864648
Validation loss decreased (inf --> 0.626054).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.644291639328003
Epoch: 2, Steps: 18 | Train Loss: 0.8881327 Vali Loss: 0.4275118 Test Loss: 3.9905517
Validation loss decreased (0.626054 --> 0.427512).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.419766902923584
Epoch: 3, Steps: 18 | Train Loss: 0.6913424 Vali Loss: 0.3230728 Test Loss: 3.3328071
Validation loss decreased (0.427512 --> 0.323073).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.354515552520752
Epoch: 4, Steps: 18 | Train Loss: 0.5332505 Vali Loss: 0.3371170 Test Loss: 3.1360302
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.5626776218414307
Epoch: 5, Steps: 18 | Train Loss: 0.4740813 Vali Loss: 0.2409065 Test Loss: 2.9160516
Validation loss decreased (0.323073 --> 0.240906).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.5466084480285645
Epoch: 6, Steps: 18 | Train Loss: 0.4420156 Vali Loss: 0.3337357 Test Loss: 2.9761391
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.8404030799865723
Epoch: 7, Steps: 18 | Train Loss: 0.4413940 Vali Loss: 0.2925201 Test Loss: 2.9212098
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.6660642623901367
Epoch: 8, Steps: 18 | Train Loss: 0.4292013 Vali Loss: 0.3198213 Test Loss: 2.8737504
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:2.894566059112549, mae:1.149371862411499
Test learner: 0 test 158
mse:4.175046443939209, mae:1.437593936920166
Test learner: 1 test 158
mse:4.653385639190674, mae:1.592789888381958
Test learner: 2 test 158
mse:5.329777240753174, mae:1.58162522315979
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.0040435480756849575
stdev: 0.009402813584933889
stdev: 0.005089631143355978
stdev: 0.005448386699276298
stdev: 0.0014131585762210013
stdev: 0.0020707073998624736
stdev: 0.005841607456447519
stdev: 0.001493055964133239
stdev: 0.003704688448286261
stdev: 0.004402757713752216
stdev: 0.006480962759697463
stdev: 0.008414428831214824
stdev: 0.0026460533528884123
stdev: 0.008082095550588086
stdev: 0.0038024873107643338
stdev: 0.007943626678150583
stdev: 0.009234545181900405
stdev: 0.003036445563629472
stdev: 0.009920439227526324
stdev: 0.0038031994650529768
stdev: 0.008970750596564325
stdev: 0.007242648894589634
stdev: 0.001490722533978015
stdev: 0.0028163694934197235
stdev: 0.00873240227592173
stdev: 0.00694681045314295
stdev: 0.008855081094057221
stdev: 0.007513703699165961
stdev: 0.001827446662939766
stdev: 0.0011976944599024545
stdev: 0.002638440948158871
stdev: 0.0034852161694518707
stdev: 0.007059999489706122
stdev: 0.00613427377696895
stdev: 0.004395762422816739
stdev: 0.0035606167405881754
stdev: 0.002823993072755853
stdev: 0.00397841073416727
>>>>>>>start training URT: ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Train URT layer >>>>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Best MSE: 10000000000.0
Epoch: 1 cost time: 2.7262725830078125
Update Best URT params
Epoch: 1, Steps: 18 | Train Loss: 0.5185181 Vali Loss: 0.3233872 Test Loss: 3.0123053
Validation loss decreased (inf --> 0.323387).  Saving model ...
Epoch: 2 cost time: 2.5852086544036865
Update Best URT params
Epoch: 2, Steps: 18 | Train Loss: 0.5020937 Vali Loss: 0.2941778 Test Loss: 3.0006680
Validation loss decreased (0.323387 --> 0.294178).  Saving model ...
Epoch: 3 cost time: 2.613723039627075
Update Best URT params
Epoch: 3, Steps: 18 | Train Loss: 0.4814903 Vali Loss: 0.2819464 Test Loss: 2.9980404
Validation loss decreased (0.294178 --> 0.281946).  Saving model ...
Epoch: 4 cost time: 2.6348934173583984
Epoch: 4, Steps: 18 | Train Loss: 0.4970718 Vali Loss: 0.2828392 Test Loss: 3.0607269
EarlyStopping counter: 1 out of 3
Epoch: 5 cost time: 2.4893062114715576
Update Best URT params
Epoch: 5, Steps: 18 | Train Loss: 0.5004183 Vali Loss: 0.2798237 Test Loss: 3.0333095
Validation loss decreased (0.281946 --> 0.279824).  Saving model ...
Epoch: 6 cost time: 2.4239883422851562
Epoch: 6, Steps: 18 | Train Loss: 0.4923521 Vali Loss: 0.3058779 Test Loss: 3.0158527
EarlyStopping counter: 1 out of 3
Epoch: 7 cost time: 2.357377767562866
Epoch: 7, Steps: 18 | Train Loss: 0.5040466 Vali Loss: 0.2917033 Test Loss: 3.0191936
EarlyStopping counter: 2 out of 3
Epoch: 8 cost time: 2.6569018363952637
Epoch: 8, Steps: 18 | Train Loss: 0.5111043 Vali Loss: 0.3135206 Test Loss: 3.0677135
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing FastSlow+URT : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:3.0279738903045654, mae:1.1929041147232056
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.0042808587230366395
stdev: 0.0028234384947666406
stdev: 0.006426592856368131
stdev: 0.0015666237959113694
stdev: 0.007583301422937549
stdev: 0.0076045976661121215
stdev: 0.006311352189153682
stdev: 0.007452157032140526
stdev: 0.007418486467806796
stdev: 0.007982823597325788
stdev: 0.007156453573165013
stdev: 0.00818107833254179
stdev: 0.006300900794710145
stdev: 0.0087374688445465
stdev: 0.004979929427326386
stdev: 0.004491869918672758
stdev: 0.003530137591452979
stdev: 0.0018579698383583564
stdev: 0.004901020555393326
stdev: 0.007085464410959132
stdev: 0.0032563542868208222
stdev: 0.0040567829206616035
stdev: 0.006719029937464292
stdev: 0.007128856247841697
stdev: 0.004152032303254075
stdev: 0.005553610170122295
stdev: 0.004707060556511586
stdev: 0.0076803528583990295
stdev: 0.002304681616882927
stdev: 0.007580956287707459
stdev: 0.005638575534216023
stdev: 0.003993610189887777
stdev: 0.009330527683911374
stdev: 0.009760566603429548
stdev: 0.00603585480018269
stdev: 0.001916998169316187
stdev: 0.0070487111303112245
stdev: 0.009376417330829077
>>>>>>>start training URT: ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
Train URT layer >>>>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Best MSE: 10000000000.0
Epoch: 1 cost time: 2.4477345943450928
Update Best URT params
Epoch: 1, Steps: 18 | Train Loss: 0.5370688 Vali Loss: 0.2683056 Test Loss: 2.9034333
Validation loss decreased (inf --> 0.268306).  Saving model ...
Epoch: 2 cost time: 2.32108736038208
Epoch: 2, Steps: 18 | Train Loss: 0.5219393 Vali Loss: 0.2723837 Test Loss: 2.9179058
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 2.465355157852173
Epoch: 3, Steps: 18 | Train Loss: 0.5270158 Vali Loss: 0.2851799 Test Loss: 2.9480910
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 2.4357223510742188
Epoch: 4, Steps: 18 | Train Loss: 0.5239831 Vali Loss: 0.2849216 Test Loss: 2.9562805
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing FastSlow+URT : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:2.8918182849884033, mae:1.1706037521362305
Use GPU: cuda:0
Check c_out
7
Check c_out
7
Check c_out
7
[CREATE] 3 learners of Autoformer
stdev: 0.0035668865672155953
stdev: 0.0020608504838862036
stdev: 0.008653460689915857
stdev: 0.007260126464970977
stdev: 0.009096712331068756
stdev: 0.009476542441457021
stdev: 0.0056470240360343375
stdev: 0.007253809346852582
stdev: 0.004883289095696004
stdev: 0.008865450137393299
stdev: 0.0068958067696628005
stdev: 0.0018259990394759195
stdev: 0.003640881387783723
stdev: 0.003671529032511444
stdev: 0.004001384044156965
stdev: 0.002061214059206999
stdev: 0.00630607430266911
stdev: 0.005385761593035615
stdev: 0.0019330568466263006
stdev: 0.0036480190271133196
stdev: 0.0066437063489144955
stdev: 0.0016611641676015847
stdev: 0.002516175249459441
stdev: 0.007369719946290036
stdev: 0.0063511188026476395
stdev: 0.005628800985083237
stdev: 0.005818564498524979
stdev: 0.003332552853647164
stdev: 0.006994906747097796
stdev: 0.001253748680053103
stdev: 0.007158257097549597
stdev: 0.006257416307763041
stdev: 0.006030380024144336
stdev: 0.0022584976136135783
stdev: 0.0021508918060897807
stdev: 0.005901494288322307
stdev: 0.006094700802544767
stdev: 0.008340136802729064
>>>>>>>start training URT: ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
Train URT layer >>>>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Best MSE: 10000000000.0
Epoch: 1 cost time: 2.575856924057007
Update Best URT params
Epoch: 1, Steps: 18 | Train Loss: 0.5296060 Vali Loss: 0.2699415 Test Loss: 2.9925647
Validation loss decreased (inf --> 0.269942).  Saving model ...
Epoch: 2 cost time: 2.474916458129883
Epoch: 2, Steps: 18 | Train Loss: 0.5230377 Vali Loss: 0.2893780 Test Loss: 2.9729562
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 2.459326982498169
Epoch: 3, Steps: 18 | Train Loss: 0.5110275 Vali Loss: 0.2859265 Test Loss: 2.9964759
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 2.446690797805786
Epoch: 4, Steps: 18 | Train Loss: 0.5200356 Vali Loss: 0.2809307 Test Loss: 2.9955752
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing FastSlow+URT : ili_E3k_36_36_B6autoformer_custom_ftM_sl36_ll18_pl36_dm256_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
test shape: (158, 36, 7) (158, 36, 7)
mse:2.9736006259918213, mae:1.1645948886871338
